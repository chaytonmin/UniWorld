# UniWorld: Multi-camera Spatio-temporal Pre-Training via World Models 

> [Paper in arXiv](xxx) 

# Abstract
Humans possess an inherent spatial-temporal world model that allows them to mentally reconstruct their surroundings and predict future changes, which is crucial for understanding the surrounding 4D dynamic world. In this paper, we imbue the autonomous vehicle with a similar spatial-temporal world model to perceive its surroundings and predict the future behaviour of other traffic participants. We propose a unified pre-training method based on world models, called UniWorld, which involves initially predicting 4D geometric occupancy as the foundational stage and subsequently fine-tuning the model on downstream tasks. Besides, UniWorld's pre-training process is label-free, enabling the utilization of massive amounts of image-LiDAR data collected by autonomous vehicles for effective pre-training.

# Bibtex
If this work is helpful for your research, please consider citing the following BibTeX entry.

```
@article{UniWorld,
  title={UniWorld: Multi-camera Spatio-temporal Pre-Training via World Models},
  author={Chen Min, Dawei Zhao, Liang Xiao, Yiming Nie, and Bin Dai}
  journal={arXiv preprint},
  year={2023}
}
```
```
@article{occ-bev,
  title={Occ-BEV: Multi-Camera Unified Pre-training via 3D Scene Reconstruction},
  author={Chen Min, Xinli Xu, Dawei Zhao, Liang Xiao, Yiming Nie, and Bin Dai}
  journal={arXiv preprint},
  year={2023}
}
```
